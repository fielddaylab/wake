{
   "__serializerVersion": 2,
   "jobs": [
      {
         "id": "arctic-missing-whale",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
         ],
         "requiredUpgrades": [
            {
               "id": "ROVScanner",
               "date": {
                  "added": 1.32953898419312E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 0,
            "argumentation": 2,
            "topicComplexity": 1
         },
         "tasks": [
            {
               "id": "findWhale",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Detritus",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "W_WhaleFall",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "findWhale",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "findTracker",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "foundDetritus",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "findTracker",
               "date": {
                  "added": 1.3294107995602E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "WhaleTracker",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "foundDetritus",
               "date": {
                  "added": 1.3294107995602E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "findWhale",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "W_WhaleFall.Population.Detritus",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            }
         ]
      },
      {
         "id": "arctic-time-of-death",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "arctic-disappearing-act",
               "date": {
                  "added": 1.32953970272584E+17
               }
            },
            {
               "id": "arctic-time-of-death",
               "date": {
                  "added": 1.32953970272584E+17,
                  "deprecated": 1.3295916222049E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "ProbeHacker",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "Microscope",
               "date": {
                  "added": 1.3305916268445E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 0,
            "argumentation": 5,
            "topicComplexity": 2
         },
         "tasks": [
            {
               "id": "getPopulations",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.3294107995602E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 3,
               "scaffoldingComplexity": 3,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "getPops",
               "date": {
                  "added": 1.3294107995602E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "W_WhaleFall.Population.ArcticCod",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "W_WhaleFall.Population.BristleWorm",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "W_WhaleFall.Population.Detritus",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "W_WhaleFall.Population.Hagfish",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "W_WhaleFall.Population.IceAlgae",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "W_WhaleFall.Population.NorthAtlanticOctopus",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "W_WhaleFall.Population.SalmonShark",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "W_WhaleFall.Population.SnowCrab",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "W_WhaleFall.Population.ZombieWorm",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "W_WhaleFall.Population.ChinookSalmon",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            }
         ]
      },
      {
         "id": "arctic-whale-csi",
         "date": {
            "added": 1.32914936623526E+17,
            "deprecated": 1.33138730177673E+17
         },
         "requiredJobs": [
         ],
         "requiredUpgrades": [
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 0,
            "argumentation": 0,
            "topicComplexity": 0
         },
         "tasks": [
            {
               "id": "scanAndTag",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.33313284421198E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "scanIceAlgae",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.33313284421198E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.33313284421198E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "displaced-reef",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
         ],
         "requiredUpgrades": [
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 0,
            "argumentation": 2,
            "topicComplexity": 1
         },
         "tasks": [
            {
               "id": "visitSiteO",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Travel",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "getScans",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "visitSiteO",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "LoggerheadTurtle",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "SeaPearl",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "AngelFish",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "RedGrouper",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "ElkhornCoral",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "getCounts",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "getScans",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "O_OilRig.Population.LoggerheadTurtle",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "O_OilRig.Population.AngelFish",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "O_OilRig.Population.RedGrouper",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "O_OilRig.Population.SeaPearl",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "O_OilRig.Population.ElkhornCoral",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "getCounts",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "makeModel",
               "date": {
                  "added": 1.3305916268445E+17,
                  "deprecated": 1.33313284421198E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "hide-n-seek",
         "date": {
            "added": 1.32914936623526E+17,
            "deprecated": 1.3295916222049E+17
         },
         "requiredJobs": [
            {
               "id": "turtle-danger2",
               "date": {
                  "added": 1.32953970272584E+17,
                  "deprecated": 1.3295916222049E+17
               }
            },
            {
               "id": "hide-n-seek",
               "date": {
                  "added": 1.32953970272584E+17,
                  "deprecated": 1.3295916222049E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "Flashlight",
               "date": {
                  "added": 1.32953898419312E+17,
                  "deprecated": 1.3295916222049E+17
               }
            },
            {
               "id": "MeasurementTank",
               "date": {
                  "added": 1.32953898419312E+17,
                  "deprecated": 1.3295916222049E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 3,
            "modeling": 4,
            "argumentation": 1,
            "topicComplexity": 0
         },
         "tasks": [
            {
               "id": "jellyScan",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.3295916222049E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "jellyObservation",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.3295916222049E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "jellyRates",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.3295916222049E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "jellyPrediction",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.3295916222049E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.3295916222049E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "bayou-oxygen-tracking",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "bayou-shrimp-tastrophe",
               "date": {
                  "added": 1.32953970272584E+17,
                  "deprecated": 1.33111006512628E+17
               }
            },
            {
               "id": "bayou-shrimp-yields",
               "date": {
                  "added": 1.33111006512628E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "ROVScanner",
               "date": {
                  "added": 1.33111006512628E+17
               }
            },
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.33111006512628E+17
               }
            },
            {
               "id": "VisualModel",
               "date": {
                  "added": 1.33111006512628E+17
               }
            },
            {
               "id": "SyncModel",
               "date": {
                  "added": 1.33111006512628E+17
               }
            },
            {
               "id": "ObservationTank",
               "date": {
                  "added": 1.33111006512628E+17
               }
            },
            {
               "id": "MeasurementTank",
               "date": {
                  "added": 1.33111006512628E+17
               }
            },
            {
               "id": "Microscope",
               "date": {
                  "added": 1.33111006512628E+17
               }
            },
            {
               "id": "WaterModeling",
               "date": {
                  "added": 1.33111006512628E+17
               }
            },
            {
               "id": "ProbeHacker",
               "date": {
                  "added": 1.33111006512628E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 3,
            "modeling": 3,
            "argumentation": 4,
            "topicComplexity": 3
         },
         "tasks": [
            {
               "id": "getScans",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.33111006512628E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "measureOxygenUsage",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.33111006512628E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "createModel",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.33111006512628E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "makeVisual",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "scanAll",
               "date": {
                  "added": 1.33111006512628E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Cyanobacteria",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "WhiteShrimp",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "DecomposingBacteria",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Detritus",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "measureCritters",
               "date": {
                  "added": 1.33111006512628E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "scanAll",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Cyanobacteria.Produce.Oxygen",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "DecomposingBacteria.Consume.Oxygen",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "WhiteShrimp.Consume.Oxygen",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "makeVisual",
               "date": {
                  "added": 1.33111006512628E+17
               },
               "category": "Model",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "measureCritters",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "P_DeadZone.Model.OxygenTracking.Visual",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            }
         ]
      },
      {
         "id": "reef-decision",
         "date": {
            "added": 1.32914936623526E+17,
            "deprecated": 1.3295916222049E+17
         },
         "requiredJobs": [
            {
               "id": "turtle-danger2",
               "date": {
                  "added": 1.32953970272584E+17,
                  "deprecated": 1.3295916222049E+17
               }
            },
            {
               "id": "reef-decision",
               "date": {
                  "added": 1.32953970272584E+17,
                  "deprecated": 1.3295916222049E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "InterveneModel",
               "date": {
                  "added": 1.32953898419312E+17,
                  "deprecated": 1.3295916222049E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 4,
            "argumentation": 1,
            "topicComplexity": 0
         },
         "tasks": [
            {
               "id": "interventionDecision",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.3295916222049E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.3295916222049E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "bayou-save-our-shrimp",
         "date": {
            "added": 1.32914936623526E+17,
            "deprecated": 1.33111006512628E+17
         },
         "requiredJobs": [
            {
               "id": "bayou-save-our-shrimp",
               "date": {
                  "added": 1.32953970272584E+17,
                  "deprecated": 1.33111006512628E+17
               }
            }
         ],
         "requiredUpgrades": [
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 0,
            "argumentation": 0,
            "topicComplexity": 0
         },
         "tasks": [
            {
               "id": "getScans",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.33111006512628E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.33111006512628E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "bayou-shrimp-tastrophe",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "bayou-save-our-shrimp",
               "date": {
                  "added": 1.32953970272584E+17,
                  "deprecated": 1.33111006512628E+17
               }
            },
            {
               "id": "bayou-dirty-detritus",
               "date": {
                  "added": 1.33111006512628E+17
               }
            },
            {
               "id": "bayou-oxygen-tracking",
               "date": {
                  "added": 1.33111006512628E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "ROVScanner",
               "date": {
                  "added": 1.33111006512628E+17
               }
            },
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.33111006512628E+17
               }
            },
            {
               "id": "VisualModel",
               "date": {
                  "added": 1.33111006512628E+17
               }
            },
            {
               "id": "SyncModel",
               "date": {
                  "added": 1.33111006512628E+17
               }
            },
            {
               "id": "ObservationTank",
               "date": {
                  "added": 1.33111006512628E+17
               }
            },
            {
               "id": "MeasurementTank",
               "date": {
                  "added": 1.33111006512628E+17
               }
            },
            {
               "id": "ProbeHacker",
               "date": {
                  "added": 1.33311514440551E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 5,
            "modeling": 5,
            "argumentation": 5,
            "topicComplexity": 3
         },
         "tasks": [
            {
               "id": "measureOxygen",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.33111006512628E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 3,
               "scaffoldingComplexity": 3,
               "requiredTasks": [
                  {
                     "id": "createModel",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "createModel",
               "date": {
                  "added": 1.33111006512628E+17
               },
               "category": "Model",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "P_DeadZone.Model.Shrimptastrophe.Sync",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            }
         ]
      },
      {
         "id": "turtle-danger",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "displaced-reef",
               "date": {
                  "added": 1.32953970272584E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "ObservationTank",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "Microscope",
               "date": {
                  "added": 1.32953898419312E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 1,
            "modeling": 1,
            "argumentation": 4,
            "topicComplexity": 2
         },
         "tasks": [
            {
               "id": "experimentsForSiteO",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "countCyano",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "LoggerheadTurtle.Eats.AngelFish",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "LoggerheadTurtle.Eats.Cyanobacteria",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "visualModelO",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Model",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "experimentsForSiteO",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "O_OilRig.turtleDanger.Model.Visual",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "visualModelO",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "scanCyano",
               "date": {
                  "added": 1.3294107995602E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Cyanobacteria",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "countCyano",
               "date": {
                  "added": 1.3294107995602E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "scanCyano",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "O_OilRig.Population.Cyanobacteria",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            }
         ]
      },
      {
         "id": "turtle-danger2",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "turtle-danger",
               "date": {
                  "added": 1.32953970272584E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "ProbeHacker",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "MeasurementTank",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "PredictionModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "VisualModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ROVScanner",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "Microscope",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "StressTank",
               "date": {
                  "added": 1.3305916268445E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 4,
            "modeling": 3,
            "argumentation": 1,
            "topicComplexity": 3
         },
         "tasks": [
            {
               "id": "historicalData",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "O_OilRig.PopulationHistory.LoggerheadTurtle",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "syncModel",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Model",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "measureStress",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "O_OilRig.turtleDanger.Model.Describe",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "syncModel",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "measureStress",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Experiment",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "historicalData",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "AngelFish.Light.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Cyanobacteria.Light.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "ElkhornCoral.Light.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "RedGrouper.Light.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "SeaPearl.Light.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            }
         ]
      },
      {
         "id": "coral-casting-shade",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "coral-stressed",
               "date": {
                  "added": 1.32953970272584E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "ProbeHacker",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "MeasurementTank",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "StressTank",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "PropGuard",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "VisualModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "SyncModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ROVScanner",
               "date": {
                  "added": 1.32953898419312E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 3,
            "modeling": 3,
            "argumentation": 1,
            "topicComplexity": 2
         },
         "tasks": [
            {
               "id": "scanSarg",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Sargassum",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "popProbe",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "scanSarg",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "SargassumCoveredReef.PopulationHistory.Sargassum",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "chemHistory",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "scanSarg",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "SargassumCoveredReef.Temperature.History",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "SargassumCoveredReef.WaterChemHistory.Light",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "sargGrowthRate",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "chemHistory",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "popProbe",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "UpgradeFact",
                     "id": "Sargassum.Reproduce",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "sargLight",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "chemHistory",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "popProbe",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Sargassum.Consume.Light",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "coralGrowthRate",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "chemHistory",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "popProbe",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "StaghornCoral.Reproduce",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "coralGrowthStressed",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "chemHistory",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "popProbe",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "StaghornCoral.Reproduce.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "sargModel",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Model",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "coralGrowthStressed",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "sargLight",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "sargGrowthRate",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "coralGrowthRate",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "coralLight",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "SargassumCoveredReef.Model.LightPrediction",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "sargArgue",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "sargModel",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "coralLight",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "chemHistory",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "popProbe",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "StaghornCoral.Consume.Light",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            }
         ]
      },
      {
         "id": "coral-eat-seaweed",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "coral-casting-shade",
               "date": {
                  "added": 1.32953970272584E+17
               }
            }
         ],
         "requiredUpgrades": [
         ],
         "difficulties": {
            "experimentation": 2,
            "modeling": 0,
            "argumentation": 2,
            "topicComplexity": 0
         },
         "tasks": [
            {
               "id": "urchinSarg",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Urchin.Eats.Sargassum.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "urchinSargArgue",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "urchinSarg",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "coral-fake-fix",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "coral-turtle-population",
               "date": {
                  "added": 1.32953970272584E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "ProbeHacker",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "VisualModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 0,
            "argumentation": 4,
            "topicComplexity": 2
         },
         "tasks": [
            {
               "id": "findReef",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Travel",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "scanProbes",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "LionfishInvasion.PopulationHistory.Lionfish",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "LionfishInvasion.PopulationHistory.Fishers",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "countPopulation",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "LionfishInvasion.Population.StaghornCoral",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "LionfishInvasion.Population.ArtificialReef",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "argue",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "findReef",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "scanProbes",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "countPopulation",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "coral-fishy-bizz",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
         ],
         "requiredUpgrades": [
            {
               "id": "ProbeHacker",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "InterveneModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "VisualModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.32953898419312E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 4,
            "argumentation": 3,
            "topicComplexity": 2
         },
         "tasks": [
            {
               "id": "getScans",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Fishers",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "RedGrouper",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "ReefEdge.Population.Fishers",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Fishers.Eats.RedGrouper",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "historicalPopulations",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "ReefEdge.PopulationHistory.RedGrouper",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "ReefEdge.PopulationHistory.Fishers",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "getModel",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Model",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "getScans",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "historicalPopulations",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "ReefEdge.Model.GrouperFishingRate",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "getModel",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "coral-hunting-lions",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "coral-lionfish-conspiracy",
               "date": {
                  "added": 1.32953970272584E+17
               }
            },
            {
               "id": "coral-hunting-lions",
               "date": {
                  "added": 1.32953970272584E+17,
                  "deprecated": 1.3305916268445E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "PredictionModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "InterveneModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "MeasurementTank",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "VisualModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ProbeHacker",
               "date": {
                  "added": 1.3305916268445E+17
               }
            },
            {
               "id": "Microscope",
               "date": {
                  "added": 1.3305916268445E+17
               }
            },
            {
               "id": "StressTank",
               "date": {
                  "added": 1.33067919669553E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 5,
            "modeling": 5,
            "argumentation": 5,
            "topicComplexity": 2
         },
         "tasks": [
            {
               "id": "scanSpear",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.3305916268445E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "scanCritters",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "BlueheadWrasse",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "BlueTang",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Lionfish",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "RedGrouper",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Sargassum",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "StaghornCoral",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "TurfAlgae",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Ick",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Fishers",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "scanHistory",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "LionfishInvasion.Light.History",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "LionfishInvasion.PopulationHistory.Lionfish",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "countPopulation",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "LionfishInvasion.Population.BlueheadWrasse",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "LionfishInvasion.Population.BlueTang",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "LionfishInvasion.Population.Lionfish",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "LionfishInvasion.Population.StaghornCoral",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "LionfishInvasion.Population.Sargassum",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "LionfishInvasion.Population.Ick",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "observeEatRules",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "countPopulation",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Lionfish.Eats.BlueheadWrasse",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Lionfish.Eats.BlueTang",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "BlueTang.Eats.TurfAlgae",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "BlueheadWrasse.Eats.Ick",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "obtainStressRules",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "observeEatRules",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "BlueheadWrasse.Light.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "BlueheadWrasse.PH.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "BlueheadWrasse.Temperature.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "BlueTang.Light.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "BlueTang.PH.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "BlueTang.Temperature.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Sargassum.Light.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Sargassum.PH.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Sargassum.Temperature.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "StaghornCoral.Light.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "StaghornCoral.PH.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "StaghornCoral.Temperature.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "TurfAlgae.Light.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "TurfAlgae.PH.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "TurfAlgae.Temperature.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Lionfish.Light.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Lionfish.Temperature.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "StaghornCoral.Reproduce.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "measureStressEatRates",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.3305916268445E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "measureStressReproduceRates",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "measureEatRates",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "StaghornCoral.Reproduce",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "BlueheadWrasse.Reproduce",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "BlueTang.Reproduce",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Lionfish.Reproduce",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "TurfAlgae.Reproduce",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Sargassum.Reproduce",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Ick.Reproduce",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "obtainChemistry",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "measureStressReproduceRates",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Sargassum.Consume.CO2",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Sargassum.Produce.Oxygen",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Sargassum.Consume.Light",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "StaghornCoral.Consume.CO2",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "StaghornCoral.Produce.Oxygen",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "StaghornCoral.Consume.Light",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Lionfish.Consume.Oxygen",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Lionfish.Produce.CarbonDioxide",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "BlueheadWrasse.Consume.Oxygen",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "BlueheadWrasse.Produce.CarbonDioxide",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "BlueTang.Consume.Oxygen",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "BlueTang.Produce.CarbonDioxide",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "TurfAlgae.Consume.Light",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "TurfAlgae.Produce.Oxygen",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "TurfAlgae.Consume.CarbonDioxide",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "predictModel",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Model",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "obtainChemistry",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "LionfishInvasion.Model.HuntingLionsPrediction",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "interveneModel",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Model",
               "taskComplexity": 3,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "predictModel",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "LionfishInvasion.Model.HuntingLionsIntervene",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "argueIncentive",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 3,
               "scaffoldingComplexity": 3,
               "requiredTasks": [
                  {
                     "id": "interveneModel",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "measureEatRates",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Experiment",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "obtainStressRules",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "UpgradeFact",
                     "id": "Lionfish.Eats.BlueheadWrasse",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "UpgradeFact",
                     "id": "Lionfish.Eats.BlueTang",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "UpgradeFact",
                     "id": "BlueTang.Eats.TurfAlgae",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "UpgradeFact",
                     "id": "BlueheadWrasse.Eats.Ick",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            }
         ]
      },
      {
         "id": "coral-lionfish-conspiracy",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "coral-fake-fix",
               "date": {
                  "added": 1.32953970272584E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "ObservationTank",
               "date": {
                  "added": 1.32953898419312E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 1,
            "modeling": 0,
            "argumentation": 3,
            "topicComplexity": 1
         },
         "tasks": [
            {
               "id": "scanNew",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "BlueheadWrasse",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "BlueTang",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Lionfish",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "observeInteractions",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "observeCoral",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Lionfish.Eats.BlueTang",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Lionfish.Eats.BlueheadWrasse",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "arguePredator",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "observeInteractions",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "observeCoral",
               "date": {
                  "added": 1.33080912981555E+17
               },
               "category": "Experiment",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "scanNew",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "coral-much-algae",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "coral-fake-fix",
               "date": {
                  "added": 1.32953970272584E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "MeasurementTank",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "SyncModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 3,
            "modeling": 3,
            "argumentation": 3,
            "topicComplexity": 2
         },
         "tasks": [
            {
               "id": "scanAll",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "RedGrouper",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Lionfish",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "StaghornCoral",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "BlueTang",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "BlueheadWrasse",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "TurfAlgae",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Sargassum",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "observeEatAlgae",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "scanAll",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "BlueTang.Eats.TurfAlgae",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "measureEatRate",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "observeEatAlgae",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "UpgradeFact",
                     "id": "BlueTang.Eats.TurfAlgae",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "modelPopulations",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Model",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "measureEatRate",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "LionfishInvasion.Model.MuchAlgaeDescriptive",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "modelPopulations",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "histPop",
               "date": {
                  "added": 1.32953898419312E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "scanAll",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "LionfishInvasion.PopulationHistory.Lionfish",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "LionfishInvasion.PopulationHistory.StaghornCoral",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "LionfishInvasion.PopulationHistory.Fishers",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            }
         ]
      },
      {
         "id": "coral-ocean-plastics",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
         ],
         "requiredUpgrades": [
            {
               "id": "VisualModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "PropGuard",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "Microscope",
               "date": {
                  "added": 1.3305916268445E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 2,
            "modeling": 0,
            "argumentation": 1,
            "topicComplexity": 1
         },
         "tasks": [
            {
               "id": "scanReefEdge",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "LoggerheadTurtle",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Copepod",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "QueenConch",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "WhiteShrimp",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "StaghornCoral",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "whatTurtlesEat",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "scanReefEdge",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "LoggerheadTurtle.Eats.QueenConch",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "LoggerheadTurtle.Eats.WhiteShrimp",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "LoggerheadTurtle.Eats.Copepod",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "LoggerheadTurtle.Eats.PlasticBag",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "whatTurtlesEat",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "makeModel",
               "date": {
                  "added": 1.3305916268445E+17,
                  "deprecated": 1.33313284421198E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "coral-stressed",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
         ],
         "requiredUpgrades": [
            {
               "id": "StressTank",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "PropGuard",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "VisualModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.32953898419312E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 2,
            "modeling": 0,
            "argumentation": 4,
            "topicComplexity": 2
         },
         "tasks": [
            {
               "id": "siteR",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "StaghornCoral",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "SargassumCoveredReef",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "stressCoral",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "siteR",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "StaghornCoral.Light.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "stressCoral",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "coral-turtle-population",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
         ],
         "requiredUpgrades": [
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 0,
            "argumentation": 1,
            "topicComplexity": 0
         },
         "tasks": [
            {
               "id": "scanTurtle",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "LoggerheadTurtle",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "turtleModel",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.33313284421198E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "countTurtle",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "countTurtle",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "scanTurtle",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "ReefEdge.Population.LoggerheadTurtle",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            }
         ]
      },
      {
         "id": "coral-turtle-stability",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
         ],
         "requiredUpgrades": [
            {
               "id": "Microscope",
               "date": {
                  "added": 1.32953898419312E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 1,
            "modeling": 1,
            "argumentation": 1,
            "topicComplexity": 1
         },
         "tasks": [
            {
               "id": "scanAll",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "LoggerheadTurtle",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Copepod",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "QueenConch",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "WhiteShrimp",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "StaghornCoral",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "behavior",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "scanAll",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "LoggerheadTurtle.Eats.QueenConch",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "LoggerheadTurtle.Eats.WhiteShrimp",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "LoggerheadTurtle.Eats.Copepod",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "turtleModel",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Model",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "behavior",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "ReefEdge.Model.TurtleVisual",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "turtleModel",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "coral-urchin-friends",
         "date": {
            "added": 1.32914936623526E+17,
            "deprecated": 1.33138730177673E+17
         },
         "requiredJobs": [
            {
               "id": "coral-urchin-friends",
               "date": {
                  "added": 1.32953970272584E+17,
                  "deprecated": 1.33138730177673E+17
               }
            }
         ],
         "requiredUpgrades": [
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 0,
            "argumentation": 0,
            "topicComplexity": 0
         },
         "tasks": [
            {
               "id": "coralUrchinModel",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.33138730177673E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "urchinStressed",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.33138730177673E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "siteRModel",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.33138730177673E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "present",
               "date": {
                  "added": 1.32914936623526E+17,
                  "deprecated": 1.33138730177673E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "kelp-bull-kelp-forest",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "kelp-welcome",
               "date": {
                  "added": 1.32953970272584E+17
               }
            }
         ],
         "requiredUpgrades": [
         ],
         "difficulties": {
            "experimentation": 1,
            "modeling": 0,
            "argumentation": 1,
            "topicComplexity": 1
         },
         "tasks": [
            {
               "id": "siteA",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "BullKelp",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "foodweb",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "siteA",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Urchin.Eats.BullKelp",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "foodweb",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "kelp-energy",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "kelp-shop-welcome",
               "date": {
                  "added": 1.32953970272584E+17
               }
            }
         ],
         "requiredUpgrades": [
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 1,
            "argumentation": 1,
            "topicComplexity": 1
         },
         "tasks": [
            {
               "id": "foodweb",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Model",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "WarmKelpForest.Model.Conceptual",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "foodweb",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "kelp-mussel-fest",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "kelp-welcome",
               "date": {
                  "added": 1.33111006512628E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "StressTank",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ProbeHacker",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "VisualModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 2,
            "modeling": 0,
            "argumentation": 2,
            "topicComplexity": 2
         },
         "tasks": [
            {
               "id": "scanMussels",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Mussel",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "waterData",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "WarmKelpForest.PH.History",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "WarmKelpForest.LightHistory",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "WarmKelpForest.Temperature.History",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "stressParam",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "waterData",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "scanMussels",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Mussel.Light.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Mussel.PH.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Mussel.Temperature.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "report",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "stressParam",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "kelp-musselfest-solution",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "kelp-mussel-fest",
               "date": {
                  "added": 1.32953970272584E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "MeasurementTank",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "StressTank",
               "date": {
                  "added": 1.32953898419312E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 2,
            "modeling": 0,
            "argumentation": 3,
            "topicComplexity": 3
         },
         "tasks": [
            {
               "id": "unstressedRate",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Mussel.Reproduce",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "stressedRate",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "unstressedRate",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Mussel.Reproduce.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportChange",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "stressedRate",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "unstressedRate",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "kelp-refuge-failure",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "kelp-start-refuge",
               "date": {
                  "added": 1.32953970272584E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "MeasurementTank",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "PredictionModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ProbeHacker",
               "date": {
                  "added": 1.32953898419312E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 4,
            "modeling": 3,
            "argumentation": 3,
            "topicComplexity": 2
         },
         "tasks": [
            {
               "id": "visitSite",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Travel",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "histPop",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "visitSite",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "MixedKelp.PopulationHistory.BullKelp",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "MixedKelp.PopulationHistory.GiantKelp",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "growthRates",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "histPop",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "histChem",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "GiantKelp.Reproduce",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "GiantKelp.Reproduce.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "growthRatesBull",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "histPop",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "histChem",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "BullKelp.Reproduce",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "BullKelp.Reproduce.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "lightRatesGiant",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "histPop",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "histChem",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "GiantKelp.Consume.Light",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "lightRatesBull",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "histPop",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "histChem",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "BullKelp.Consume.Light",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "newModel",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Model",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "histPop",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "growthRates",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "growthRatesBull",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "lightRatesGiant",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "lightRatesBull",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "MixedKelp.Model.RefugeFail",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "getPaid",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 3,
               "requiredTasks": [
                  {
                     "id": "newModel",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "histChem",
               "date": {
                  "added": 1.3294107995602E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "visitSite",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "MixedKelp.PH.History",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "MixedKelp.Light.History",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "MixedKelp.Temperature.History",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            }
         ]
      },
      {
         "id": "kelp-refuge-failure-simulation",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "kelp-refuge-failure",
               "date": {
                  "added": 1.32953970272584E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "PredictionModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 4,
            "argumentation": 1,
            "topicComplexity": 2
         },
         "tasks": [
            {
               "id": "createModel",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Model",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "MixedKelp.Model.RefugeFailPredict",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "shareModel",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "createModel",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "kelp-save-urchin-barren",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "kelp-urchin-barren-predict",
               "date": {
                  "added": 1.32953970272584E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "InterveneModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 4,
            "argumentation": 2,
            "topicComplexity": 2
         },
         "tasks": [
            {
               "id": "makeAPlan",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Model",
               "taskComplexity": 3,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "UrchinBarren.Model.IntroduceOtters",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "return",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "makeAPlan",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "kelp-start-refuge",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "kelp-welcome",
               "date": {
                  "added": 1.33111006512628E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "StressTank",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "VisualModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.32953898419312E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 2,
            "modeling": 0,
            "argumentation": 4,
            "topicComplexity": 2
         },
         "tasks": [
            {
               "id": "getBullKelpStress",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "BullKelp.Light.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "BullKelp.Temperature.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "getGiantKelpStress",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "GiantKelp.Light.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "GiantKelp.Temperature.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "argueSite",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "getBullKelpStress",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "getGiantKelpStress",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "kelp-urchin-barren-predict",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "kelp-urchin-barren-viz",
               "date": {
                  "added": 1.32953970272584E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "PredictionModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 3,
            "argumentation": 1,
            "topicComplexity": 1
         },
         "tasks": [
            {
               "id": "predictSiteB",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Model",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "UrchinBarren.Model.Prediction",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "predictSiteB",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "kelp-urchin-barren-viz",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "kelp-welcome",
               "date": {
                  "added": 1.33111006512628E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "ProbeHacker",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "VisualModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.32953898419312E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 1,
            "argumentation": 1,
            "topicComplexity": 1
         },
         "tasks": [
            {
               "id": "gotoSiteB",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Travel",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "getProbeData",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "gotoSiteB",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "UrchinBarren.PopulationHistory.Urchin",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "UrchinBarren.PopulationHistory.GiantKelp",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "getTagged",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "gotoSiteB",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "UrchinBarren.Population.Urchin",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "UrchinBarren.Population.GiantKelp",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "visualSiteB",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Model",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "getProbeData",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "getTagged",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "UrchinBarren.Model.Visual",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "getProbeData",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "visualSiteB",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "kelp-urchin-farm",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
            {
               "id": "kelp-welcome",
               "date": {
                  "added": 1.33111006512628E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "MeasurementTank",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "VisualModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.32953898419312E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 3,
            "modeling": 0,
            "argumentation": 4,
            "topicComplexity": 1
         },
         "tasks": [
            {
               "id": "urchinEatBull",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "UpgradeFact",
                     "id": "Urchin.Eats.BullKelp",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "urchinEatGiant",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "UpgradeFact",
                     "id": "Urchin.Eats.GiantKelp",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "urchinEatBull",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "urchinEatGiant",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "kelp-welcome",
         "date": {
            "added": 1.32914936623526E+17
         },
         "requiredJobs": [
         ],
         "requiredUpgrades": [
         ],
         "difficulties": {
            "experimentation": 1,
            "modeling": 0,
            "argumentation": 1,
            "topicComplexity": 1
         },
         "tasks": [
            {
               "id": "gotoSiteC",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Travel",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "scanGiantKelp",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "gotoSiteC",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "GiantKelp",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "scanUrchin",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "gotoSiteC",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Urchin",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "scanOtter",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "gotoSiteC",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "SeaOtter",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "returnToShip",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Travel",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "scanOtter",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "scanUrchin",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "scanGiantKelp",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "runExperiment",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Experiment",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "returnToShip",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "SeaOtter.Eats.Urchin",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Urchin.Eats.GiantKelp",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.32914936623526E+17
               },
               "category": "Argue",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "runExperiment",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "arctic-cause-of-death",
         "date": {
            "added": 1.3294107995602E+17
         },
         "requiredJobs": [
            {
               "id": "arctic-disappearing-act",
               "date": {
                  "added": 1.32953970272584E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "PredictionModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "VisualModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ROVScanner",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "Microscope",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ProbeHacker",
               "date": {
                  "added": 1.32953898419312E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 1,
            "modeling": 0,
            "argumentation": 5,
            "topicComplexity": 3
         },
         "tasks": [
            {
               "id": "getEnvironmentData",
               "date": {
                  "added": 1.3294107995602E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "W_WhaleFall.PH.History",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "W_WhaleFall.Light.History",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "W_WhaleFall.Temperature.History",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "getPopulationData",
               "date": {
                  "added": 1.3294107995602E+17,
                  "deprecated": 1.3305916268445E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.3294107995602E+17
               },
               "category": "Argue",
               "taskComplexity": 3,
               "scaffoldingComplexity": 3,
               "requiredTasks": [
                  {
                     "id": "getEnvironmentData",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "getHistPopulationData",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "getCurrPopulationData",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "getHistPopulationData",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "W_WhaleFall.PopulationHistory.IceAlgae",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "W_WhaleFall.PopulationHistory.Diatoms",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "getCurrPopulationData",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "W_WhaleFall.Population.IceAlgae",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "W_WhaleFall.Population.Diatoms",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            }
         ]
      },
      {
         "id": "arctic-disappearing-act",
         "date": {
            "added": 1.3294107995602E+17
         },
         "requiredJobs": [
            {
               "id": "arctic-missing-whale",
               "date": {
                  "added": 1.32953970272584E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "ObservationTank",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ROVScanner",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "Microscope",
               "date": {
                  "added": 1.33311514440551E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 2,
            "modeling": 2,
            "argumentation": 1,
            "topicComplexity": 1
         },
         "tasks": [
            {
               "id": "scanCritters",
               "date": {
                  "added": 1.3294107995602E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "W_WhaleFall",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "BristleWorm",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Hagfish",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "NorthAtlanticOctopus",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "SnowCrab",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "ZombieWorm",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Detritus",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "modelInteractions",
               "date": {
                  "added": 1.3294107995602E+17
               },
               "category": "Model",
               "taskComplexity": 1,
               "scaffoldingComplexity": 3,
               "requiredTasks": [
                  {
                     "id": "scanCritters",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "W_WhaleFall.Model.WhaleFallVisual",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.3294107995602E+17
               },
               "category": "Argue",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "modelInteractions",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "arctic-isolated-instance",
         "date": {
            "added": 1.3294107995602E+17
         },
         "requiredJobs": [
            {
               "id": "arctic-stationary-survival",
               "date": {
                  "added": 1.32953970272584E+17
               }
            },
            {
               "id": "arctic-isolated-instance",
               "date": {
                  "added": 1.32953970272584E+17,
                  "deprecated": 1.3305916268445E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "StressTank",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "Flashlight",
               "date": {
                  "added": 1.32953898419312E+17,
                  "deprecated": 1.33138730940424E+17
               }
            },
            {
               "id": "Microscope",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ProbeHacker",
               "date": {
                  "added": 1.3305916268445E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 3,
            "modeling": 0,
            "argumentation": 5,
            "topicComplexity": 3
         },
         "tasks": [
            {
               "id": "scanSponge",
               "date": {
                  "added": 1.3294107995602E+17,
                  "deprecated": 1.33311514440551E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "scanAll",
               "date": {
                  "added": 1.3294107995602E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Diatoms",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Smelt",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "RibbonSeal",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "SalmonShark",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "ChinookSalmon",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "BowheadWhale",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "SnowCrab",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "SeaAnemone",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "experimentPredatorZ",
               "date": {
                  "added": 1.3294107995602E+17,
                  "deprecated": 1.3305916268445E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "findPredator",
               "date": {
                  "added": 1.3294107995602E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "discussFindings",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "PterasterObscurus",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "experimentPredatorAll",
               "date": {
                  "added": 1.3294107995602E+17
               },
               "category": "Experiment",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "findPredator",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "PterasterObscurus.Eats.GlassSponge",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "countPopulations",
               "date": {
                  "added": 1.3294107995602E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 1,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "experimentPredatorAll",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Y_IceCrevice.Population.PterasterObscurus",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "determineStress",
               "date": {
                  "added": 1.3294107995602E+17
               },
               "category": "Experiment",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "GlassSponge.Light.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "GlassSponge.PH.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "GlassSponge.Temperature.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "discussFindings",
               "date": {
                  "added": 1.3294107995602E+17
               },
               "category": "Argue",
               "taskComplexity": 3,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "checkPredator",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "determineStress",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "checkCrab",
               "date": {
                  "added": 1.3305916268445E+17,
                  "deprecated": 1.33067919669553E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "checkSeal",
               "date": {
                  "added": 1.3305916268445E+17,
                  "deprecated": 1.33067919669553E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "checkShark",
               "date": {
                  "added": 1.3305916268445E+17,
                  "deprecated": 1.33067919669553E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "reportFinal",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "countPopulations",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "determineStress",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "checkPredator",
               "date": {
                  "added": 1.33067919669553E+17
               },
               "category": "Experiment",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "scanAll",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "arctic-stationary-survival",
         "date": {
            "added": 1.3294107995602E+17
         },
         "requiredJobs": [
            {
               "id": "arctic-underneath",
               "date": {
                  "added": 1.32953970272584E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "VisualModel",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ObservationTank",
               "date": {
                  "added": 1.32953898419312E+17
               }
            },
            {
               "id": "ROVScanner",
               "date": {
                  "added": 1.32953898419312E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 1,
            "modeling": 2,
            "argumentation": 1,
            "topicComplexity": 2
         },
         "tasks": [
            {
               "id": "visualModel",
               "date": {
                  "added": 1.3294107995602E+17
               },
               "category": "Model",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "X_UnderTheIce.Model.StationaryViz",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "report",
               "date": {
                  "added": 1.3294107995602E+17
               },
               "category": "Argue",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "visualModel",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "arctic-underneath",
         "date": {
            "added": 1.3294107995602E+17
         },
         "requiredJobs": [
         ],
         "requiredUpgrades": [
            {
               "id": "Flashlight",
               "date": {
                  "added": 1.32953898419312E+17,
                  "deprecated": 1.33313284421198E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 0,
            "argumentation": 1,
            "topicComplexity": 1
         },
         "tasks": [
            {
               "id": "explore",
               "date": {
                  "added": 1.3294107995602E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "X_UnderTheIce.Population.AstarteBorealis",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "X_UnderTheIce.Population.GlassSponge",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "X_UnderTheIce.Population.NorthernSeaNettle",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.3294107995602E+17
               },
               "category": "Argue",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "explore",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "kelp-shop-welcome",
         "date": {
            "added": 1.32953898419312E+17
         },
         "requiredJobs": [
            {
               "id": "kelp-bull-kelp-forest",
               "date": {
                  "added": 1.32953970272584E+17
               }
            }
         ],
         "requiredUpgrades": [
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 0,
            "argumentation": 0,
            "topicComplexity": 0
         },
         "tasks": [
            {
               "id": "gotoShop",
               "date": {
                  "added": 1.32953898419312E+17,
                  "deprecated": 1.3305916268445E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "getTagger",
               "date": {
                  "added": 1.32953898419312E+17
               },
               "category": "Narrative",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "getVisualModel",
               "date": {
                  "added": 1.32953898419312E+17
               },
               "category": "Narrative",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "returnShip",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Travel",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "getTagger",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "getVisualModel",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "bayou-hide-n-seek",
         "date": {
            "added": 1.3295916222049E+17
         },
         "requiredJobs": [
            {
               "id": "turtle-danger2",
               "date": {
                  "added": 1.3295916222049E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "Flashlight",
               "date": {
                  "added": 1.3295916222049E+17
               }
            },
            {
               "id": "MeasurementTank",
               "date": {
                  "added": 1.3295916222049E+17
               }
            },
            {
               "id": "PredictionModel",
               "date": {
                  "added": 1.3305916268445E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 3,
            "modeling": 4,
            "argumentation": 3,
            "topicComplexity": 2
         },
         "tasks": [
            {
               "id": "jellyScan",
               "date": {
                  "added": 1.3295916222049E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "MoonJelly",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "jellyObservation",
               "date": {
                  "added": 1.3295916222049E+17
               },
               "category": "Experiment",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "jellyScan",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "LoggerheadTurtle.Eats.MoonJelly",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "jellyRates",
               "date": {
                  "added": 1.3295916222049E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "jellyObservation",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "UpgradeFact",
                     "id": "LoggerheadTurtle.Eats.MoonJelly",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "jellyPrediction",
               "date": {
                  "added": 1.3295916222049E+17
               },
               "category": "Model",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "jellyObservation",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "jellyRates",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "O_OilRig.turtleDangerJellies.Model.Predict",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.3295916222049E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "jellyPrediction",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "bayou-reef-decision",
         "date": {
            "added": 1.3295916222049E+17
         },
         "requiredJobs": [
            {
               "id": "turtle-danger2",
               "date": {
                  "added": 1.3295916222049E+17
               }
            },
            {
               "id": "bayou-hide-n-seek",
               "date": {
                  "added": 1.3295916222049E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "InterveneModel",
               "date": {
                  "added": 1.3295916222049E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 4,
            "argumentation": 1,
            "topicComplexity": 3
         },
         "tasks": [
            {
               "id": "interventionDecision",
               "date": {
                  "added": 1.3295916222049E+17
               },
               "category": "Model",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "O_OilRig.turtleDangerNoReef.Model.Intervene",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.3295916222049E+17
               },
               "category": "Argue",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "interventionDecision",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "above-n-below",
         "date": {
            "added": 1.3305916268445E+17
         },
         "requiredJobs": [
            {
               "id": "arctic-seal-habbits",
               "date": {
                  "added": 1.3305916268445E+17,
                  "deprecated": 1.33080912981555E+17
               }
            },
            {
               "id": "arctic-seal-habitats",
               "date": {
                  "added": 1.33067919669553E+17
               }
            }
         ],
         "requiredUpgrades": [
         ],
         "difficulties": {
            "experimentation": 2,
            "modeling": 1,
            "argumentation": 1,
            "topicComplexity": 1
         },
         "tasks": [
            {
               "id": "scanNew",
               "date": {
                  "added": 1.33080912981555E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "SnowCrab",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "AstarteBorealis",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "PterasterObscurus",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "ArcticCod",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "countNew",
               "date": {
                  "added": 1.33080912981555E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "scanNew",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Y_IceCrevice.Population.SnowCrab",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Y_IceCrevice.Population.AstarteBorealis",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Y_IceCrevice.Population.PterasterObscurus",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Y_IceCrevice.Population.ArcticCod",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "experimentInteractions",
               "date": {
                  "added": 1.33080912981555E+17
               },
               "category": "Experiment",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "countNew",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "RibbonSeal.Eats.ArcticCod",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "createModel",
               "date": {
                  "added": 1.33080912981555E+17
               },
               "category": "Model",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "experimentInteractions",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Y_IceCrevice.Model.AboveAndBelowVisual",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.33080912981555E+17
               },
               "category": "Argue",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "createModel",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "arctic-in-ice",
         "date": {
            "added": 1.3305916268445E+17
         },
         "requiredJobs": [
            {
               "id": "arctic-salmon-monitoring",
               "date": {
                  "added": 1.3305916268445E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "ObservationTank",
               "date": {
                  "added": 1.3305916268445E+17
               }
            },
            {
               "id": "ROVScanner",
               "date": {
                  "added": 1.3305916268445E+17
               }
            },
            {
               "id": "Microscope",
               "date": {
                  "added": 1.33067919669553E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 1,
            "modeling": 0,
            "argumentation": 2,
            "topicComplexity": 1
         },
         "tasks": [
            {
               "id": "scanAlgae",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "IceAlgae",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "countAlgae",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "scanAlgae",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Z_OpenOcean.Population.IceAlgae",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "observeEat",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Experiment",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "countAlgae",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "ArcticCod.Eats.IceAlgae",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 3,
               "requiredTasks": [
                  {
                     "id": "observeEat",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "arctic-picky-eaters",
         "date": {
            "added": 1.3305916268445E+17
         },
         "requiredJobs": [
            {
               "id": "arctic-in-ice",
               "date": {
                  "added": 1.3305916268445E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "MeasurementTank",
               "date": {
                  "added": 1.3305916268445E+17
               }
            },
            {
               "id": "Microscope",
               "date": {
                  "added": 1.3305916268445E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 3,
            "modeling": 0,
            "argumentation": 4,
            "topicComplexity": 3
         },
         "tasks": [
            {
               "id": "obtainRateAlgae",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "UpgradeFact",
                     "id": "ArcticCod.Eats.IceAlgae",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "obtainRateDiatoms",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "UpgradeFact",
                     "id": "ArcticCod.Eats.Diatoms",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "obtainRateDiatoms",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "obtainRateAlgae",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "arctic-salmon-competition",
         "date": {
            "added": 1.3305916268445E+17
         },
         "requiredJobs": [
            {
               "id": "arctic-in-ice",
               "date": {
                  "added": 1.3305916268445E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "VisualModel",
               "date": {
                  "added": 1.3305916268445E+17
               }
            },
            {
               "id": "SyncModel",
               "date": {
                  "added": 1.3305916268445E+17
               }
            },
            {
               "id": "ObservationTank",
               "date": {
                  "added": 1.3305916268445E+17
               }
            },
            {
               "id": "MeasurementTank",
               "date": {
                  "added": 1.3305916268445E+17
               }
            },
            {
               "id": "ProbeHacker",
               "date": {
                  "added": 1.33080912981555E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 1,
            "modeling": 3,
            "argumentation": 4,
            "topicComplexity": 2
         },
         "tasks": [
            {
               "id": "observeCod",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Experiment",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "ArcticCod.Eats.Diatoms",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "ArcticCod.Eats.IceAlgae",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "modelFish",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Model",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "observeCod",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Z_OpenOcean.SalmonCompetition.Model.Sync",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Argue",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "modelFish",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "arctic-salmon-monitoring",
         "date": {
            "added": 1.3305916268445E+17
         },
         "requiredJobs": [
         ],
         "requiredUpgrades": [
            {
               "id": "ROVScanner",
               "date": {
                  "added": 1.3305916268445E+17
               }
            },
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.3305916268445E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 0,
            "argumentation": 1,
            "topicComplexity": 0
         },
         "tasks": [
            {
               "id": "countSalmon",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Z_OpenOcean.Population.ChinookSalmon",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Argue",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "countSalmon",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "arctic-seal-habbits",
         "date": {
            "added": 1.3305916268445E+17,
            "deprecated": 1.33080912981555E+17
         },
         "requiredJobs": [
         ],
         "requiredUpgrades": [
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.3305916268445E+17,
                  "deprecated": 1.33313284421198E+17
               }
            },
            {
               "id": "Icebreaker",
               "date": {
                  "added": 1.3305916268445E+17,
                  "deprecated": 1.33313284421198E+17
               }
            },
            {
               "id": "Microscope",
               "date": {
                  "added": 1.3305916268445E+17,
                  "deprecated": 1.33313284421198E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 0,
            "argumentation": 1,
            "topicComplexity": 0
         },
         "tasks": [
            {
               "id": "findRibbon",
               "date": {
                  "added": 1.3305916268445E+17,
                  "deprecated": 1.33313284421198E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "findHabitat",
               "date": {
                  "added": 1.3305916268445E+17,
                  "deprecated": 1.33313284421198E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "findMicro",
               "date": {
                  "added": 1.3305916268445E+17,
                  "deprecated": 1.33313284421198E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "findPop",
               "date": {
                  "added": 1.3305916268445E+17,
                  "deprecated": 1.33313284421198E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "report",
               "date": {
                  "added": 1.3305916268445E+17,
                  "deprecated": 1.33313284421198E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "bayou-alt-energy",
         "date": {
            "added": 1.3305916268445E+17
         },
         "requiredJobs": [
            {
               "id": "bayou-boom-cause",
               "date": {
                  "added": 1.3305916268445E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "ObservationTank",
               "date": {
                  "added": 1.3305916268445E+17
               }
            },
            {
               "id": "Microscope",
               "date": {
                  "added": 1.3305916268445E+17
               }
            },
            {
               "id": "Hull",
               "date": {
                  "added": 1.3305916268445E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 1,
            "modeling": 1,
            "argumentation": 3,
            "topicComplexity": 3
         },
         "tasks": [
            {
               "id": "scanCritters",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Detritus",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "VentStar",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Methane",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "H_Gas",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "wormEat",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Experiment",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "scanCritters",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Methanogen.Eats.H_Gas",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "VentStar.Eats.Detritus.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "DeepSeaSkate.Eats.VentStar.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "BrooksiMussel.Eats.Methanogen.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "VentStar.Eats.BrooksiMussel.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Tubeworm.Eats.Methanogen",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "getModel",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Model",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "wormEat",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "N_ThermalVent.Model.Visual",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "getModel",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "bayou-boom-cause",
         "date": {
            "added": 1.3305916268445E+17
         },
         "requiredJobs": [
         ],
         "requiredUpgrades": [
            {
               "id": "Flashlight",
               "date": {
                  "added": 1.3305916268445E+17
               }
            },
            {
               "id": "Hull",
               "date": {
                  "added": 1.3305916268445E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 0,
            "argumentation": 3,
            "topicComplexity": 2
         },
         "tasks": [
            {
               "id": "methaneScan",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Methane",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "methaneTag",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "methaneScan",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "N_ThermalVent.Population.Methane",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Argue",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "methaneTag",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "bayou-methanogen",
         "date": {
            "added": 1.3305916268445E+17
         },
         "requiredJobs": [
            {
               "id": "bayou-alt-energy",
               "date": {
                  "added": 1.3305916268445E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "VisualModel",
               "date": {
                  "added": 1.3305916268445E+17
               }
            },
            {
               "id": "StressTank",
               "date": {
                  "added": 1.3305916268445E+17
               }
            },
            {
               "id": "MeasurementTank",
               "date": {
                  "added": 1.3305916268445E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 4,
            "modeling": 0,
            "argumentation": 3,
            "topicComplexity": 3
         },
         "tasks": [
            {
               "id": "EatRule",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Methanogen.Eats.H_Gas",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "UpgradeFact",
                     "id": "Methanogen.Eats.H_Gas",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "StressRanges",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Experiment",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Methanogen.Light.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Methanogen.PH.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Methanogen.Temperature.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "WaterChem",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Methanogen.Consume.CarbonDioxide",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Methanogen.Consume.CarbonDioxide.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "Reproduction",
               "date": {
                  "added": 1.3305916268445E+17,
                  "deprecated": 1.33311514440551E+17
               },
               "category": "Experiment",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "Report",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "EatRule",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "StressRanges",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "WaterChem",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "bayou-test-model",
         "date": {
            "added": 1.3305916268445E+17,
            "deprecated": 1.33138730940424E+17
         },
         "requiredJobs": [
         ],
         "requiredUpgrades": [
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 0,
            "argumentation": 0,
            "topicComplexity": 0
         },
         "tasks": [
            {
               "id": "obtainSyncModel",
               "date": {
                  "added": 1.3305916268445E+17,
                  "deprecated": 1.33313284421198E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.3305916268445E+17,
                  "deprecated": 1.33313284421198E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "coral-tang-checkup",
         "date": {
            "added": 1.3305916268445E+17
         },
         "requiredJobs": [
            {
               "id": "coral-much-algae",
               "date": {
                  "added": 1.3305916268445E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "Microscope",
               "date": {
                  "added": 1.3305916268445E+17
               }
            },
            {
               "id": "StressTank",
               "date": {
                  "added": 1.3305916268445E+17
               }
            },
            {
               "id": "MeasurementTank",
               "date": {
                  "added": 1.3305916268445E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 3,
            "modeling": 3,
            "argumentation": 2,
            "topicComplexity": 3
         },
         "tasks": [
            {
               "id": "findStress",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Experiment",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "BlueTang.Light.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "BlueTang.PH.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "BlueTang.Temperature.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "findMicro",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "findStress",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Ick",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "countIck",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "findMicro",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "LionfishInvasion.Population.Ick",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "observeIck",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Experiment",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "countIck",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Ick.Stresses.BlueTang",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reviseModels",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Model",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "observeIck",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "LionfishInvasion.Model.IckStressVisual",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "LionfishInvasion.Model.IckStressDescribe",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "report",
               "date": {
                  "added": 1.3305916268445E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "reviseModels",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "arctic-seal-habitats",
         "date": {
            "added": 1.33067919669553E+17
         },
         "requiredJobs": [
         ],
         "requiredUpgrades": [
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.33067919669553E+17
               }
            },
            {
               "id": "Icebreaker",
               "date": {
                  "added": 1.33067919669553E+17
               }
            },
            {
               "id": "Microscope",
               "date": {
                  "added": 1.33067919669553E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 0,
            "argumentation": 2,
            "topicComplexity": 2
         },
         "tasks": [
            {
               "id": "findHabitat",
               "date": {
                  "added": 1.33067919669553E+17
               },
               "category": "Travel",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Y_IceCrevice",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "findRibbon",
               "date": {
                  "added": 1.33067919669553E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "RibbonSeal",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "findMicro",
               "date": {
                  "added": 1.33067919669553E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "findHabitat",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "findRibbon",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "ArcticCopepod",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "GlacialAmphipod",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Clione",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "IceAlgae",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "countMicro",
               "date": {
                  "added": 1.33067919669553E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "findMicro",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Y_IceCrevice.Population.ArcticCopepod",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Y_IceCrevice.Population.GlacialAmphipod",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Y_IceCrevice.Population.Clione",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Y_IceCrevice.Population.IceAlgae",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "findPop",
               "date": {
                  "added": 1.33067919669553E+17,
                  "deprecated": 1.33313284421198E+17
               },
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "report",
               "date": {
                  "added": 1.33067919669553E+17
               },
               "category": "Argue",
               "taskComplexity": 1,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "countSeal",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "countMicro",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "findRibbon",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "countSeal",
               "date": {
                  "added": 1.33080912981555E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "findHabitat",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "findRibbon",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Y_IceCrevice.Population.RibbonSeal",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            }
         ]
      },
      {
         "id": "arctic-endangered-seals",
         "date": {
            "added": 1.33080912981555E+17
         },
         "requiredJobs": [
            {
               "id": "above-n-below",
               "date": {
                  "added": 1.33080912981555E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "ObservationTank",
               "date": {
                  "added": 1.33080912981555E+17
               }
            },
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.33080912981555E+17
               }
            },
            {
               "id": "ROVScanner",
               "date": {
                  "added": 1.33080912981555E+17
               }
            },
            {
               "id": "PredictionModel",
               "date": {
                  "added": 1.33080912981555E+17
               }
            },
            {
               "id": "MeasurementTank",
               "date": {
                  "added": 1.33080912981555E+17
               }
            },
            {
               "id": "Microscope",
               "date": {
                  "added": 1.33080912981555E+17
               }
            },
            {
               "id": "ProbeHacker",
               "date": {
                  "added": 1.33080912981555E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 5,
            "modeling": 4,
            "argumentation": 4,
            "topicComplexity": 2
         },
         "tasks": [
            {
               "id": "scanProbe",
               "date": {
                  "added": 1.33080912981555E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Y_IceCrevice.PopulationHistory.IceAlgae",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "modelSync",
               "date": {
                  "added": 1.33080912981555E+17
               },
               "category": "Model",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "scanProbe",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Y_IceCrevice.Model.EndangeredSealsDescribe",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "modelPredict",
               "date": {
                  "added": 1.33080912981555E+17
               },
               "category": "Model",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "modelSync",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Y_IceCrevice.Model.EndangeredSealsPredict",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.33080912981555E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "modelPredict",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "bayou-blue-waters",
         "date": {
            "added": 1.33111006512628E+17
         },
         "requiredJobs": [
            {
               "id": "bayou-shrimp-yields",
               "date": {
                  "added": 1.33111006512628E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "ROVScanner",
               "date": {
                  "added": 1.33111006512628E+17
               }
            },
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.33111006512628E+17
               }
            },
            {
               "id": "Microscope",
               "date": {
                  "added": 1.33111006512628E+17
               }
            },
            {
               "id": "StressTank",
               "date": {
                  "added": 1.33111006512628E+17
               }
            },
            {
               "id": "MeasurementTank",
               "date": {
                  "added": 1.33111006512628E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 5,
            "modeling": 0,
            "argumentation": 1,
            "topicComplexity": 2
         },
         "tasks": [
            {
               "id": "findGreen",
               "date": {
                  "added": 1.33111006512628E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Cyanobacteria",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "countGreen",
               "date": {
                  "added": 1.33111006512628E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "findGreen",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "P_DeadZone.Population.Cyanobacteria",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "stressCB",
               "date": {
                  "added": 1.33111006512628E+17
               },
               "category": "Experiment",
               "taskComplexity": 2,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "countGreen",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Cyanobacteria.Light.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Cyanobacteria.PH.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Cyanobacteria.Temperature.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "measureEffect",
               "date": {
                  "added": 1.33111006512628E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "stressCB",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Cyanobacteria.Consume.Light",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Cyanobacteria.Consume.Light.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "measureReproduce",
               "date": {
                  "added": 1.33111006512628E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "stressCB",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "Cyanobacteria.Reproduce",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "Cyanobacteria.Reproduce.Stressed",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.33111006512628E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "measureReproduce",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "measureEffect",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "bayou-dirty-detritus",
         "date": {
            "added": 1.33111006512628E+17
         },
         "requiredJobs": [
            {
               "id": "bayou-blue-waters",
               "date": {
                  "added": 1.33111006512628E+17
               }
            }
         ],
         "requiredUpgrades": [
            {
               "id": "ROVScanner",
               "date": {
                  "added": 1.33111006512628E+17
               }
            },
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.33111006512628E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 3,
            "modeling": 0,
            "argumentation": 3,
            "topicComplexity": 2
         },
         "tasks": [
            {
               "id": "scanNew",
               "date": {
                  "added": 1.33111006512628E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Cyanobacteria",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "Detritus",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "WhiteShrimp",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "DecomposingBacteria",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "countDetritus",
               "date": {
                  "added": 1.33111006512628E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "P_DeadZone.Population.Detritus",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "eatDetritus",
               "date": {
                  "added": 1.33111006512628E+17
               },
               "category": "Experiment",
               "taskComplexity": 1,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "countDetritus",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "scanNew",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "scanProbe",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "DecomposingBacteria.Eats.Detritus",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "growDetritus",
               "date": {
                  "added": 1.33111006512628E+17
               },
               "category": "Experiment",
               "taskComplexity": 3,
               "scaffoldingComplexity": 2,
               "requiredTasks": [
                  {
                     "id": "countDetritus",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "scanNew",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "scanProbe",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.33111006512628E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "eatDetritus",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  },
                  {
                     "id": "growDetritus",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "scanProbe",
               "date": {
                  "added": 1.33311514440551E+17
               },
               "category": "Argue",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "scanNew",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "P_DeadZone.PopulationHistory.Detritus",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            }
         ]
      },
      {
         "id": "bayou-shrimp-yields",
         "date": {
            "added": 1.33111006512628E+17
         },
         "requiredJobs": [
         ],
         "requiredUpgrades": [
            {
               "id": "ROVScanner",
               "date": {
                  "added": 1.33111006512628E+17
               }
            },
            {
               "id": "ROVTagger",
               "date": {
                  "added": 1.33111006512628E+17
               }
            }
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 0,
            "argumentation": 3,
            "topicComplexity": 0
         },
         "tasks": [
            {
               "id": "countShrimp",
               "date": {
                  "added": 1.33111006512628E+17
               },
               "category": "Scan_Count",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
                  {
                     "stepType": "AcquireBestiaryEntry",
                     "id": "WhiteShrimp",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  },
                  {
                     "stepType": "AcquireFact",
                     "id": "P_DeadZone.Population.WhiteShrimp",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.33111006512628E+17
               },
               "category": "Argue",
               "taskComplexity": 2,
               "scaffoldingComplexity": 1,
               "requiredTasks": [
                  {
                     "id": "countShrimp",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      },
      {
         "id": "final-final",
         "date": {
            "added": 1.33138730177673E+17
         },
         "requiredJobs": [
         ],
         "requiredUpgrades": [
         ],
         "difficulties": {
            "experimentation": 0,
            "modeling": 2,
            "argumentation": 4,
            "topicComplexity": 0
         },
         "tasks": [
            {
               "id": "tellMom",
               "date": {
                  "added": 1.33138730177673E+17
               },
               "category": "Narrative",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "createModel",
               "date": {
                  "added": 1.33138730177673E+17
               },
               "category": "Model",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "tellMom",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
                  {
                     "stepType": "AcquireFact",
                     "id": "DeepDeepSea.Model.Visual",
                     "date": {
                        "added": 1.33313401215275E+17
                     }
                  }
               ]
            },
            {
               "id": "reportBack",
               "date": {
                  "added": 1.33138730177673E+17
               },
               "category": "Argue",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "createModel",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "sneakOut",
               "date": {
                  "added": 1.33138730177673E+17
               },
               "category": "Narrative",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "reportBack",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "getUncleHelp",
               "date": {
                  "added": 1.33138730177673E+17
               },
               "category": "Narrative",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "sneakOut",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "checkShip",
               "date": {
                  "added": 1.33138730177673E+17
               },
               "category": "Narrative",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "getUncleHelp",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            },
            {
               "id": "returnToShop",
               "date": {
                  "added": 1.33138730177673E+17,
                  "deprecated": 1.33312398136518E+17
               },
               "category": "Narrative",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
               ],
               "steps": [
               ]
            },
            {
               "id": "performRescue",
               "date": {
                  "added": 1.33174634552926E+17
               },
               "category": "Narrative",
               "taskComplexity": 0,
               "scaffoldingComplexity": 0,
               "requiredTasks": [
                  {
                     "id": "checkShip",
                     "date": {
                        "added": 1.33312355881023E+17
                     }
                  }
               ],
               "steps": [
               ]
            }
         ]
      }
   ],
   "jobsSummary": {
      "experimentSummary": [
         18,
         10,
         8,
         9,
         3,
         4
      ],
      "modelingSummary": [
         27,
         6,
         3,
         8,
         6,
         2
      ],
      "argumentationSummary": [
         0,
         18,
         8,
         11,
         10,
         5
      ]
   }
}